---
title: latent space representation of the worldly causality through large language models
keywords: large language models, neural networks, monopolistic marketeering of articial intelligence, the world as will and representation, digitization and automatization through machine learning models
link-citations: true
---

concerning [[Action Humanesque]]

# The latent space representation of the worldly causality through large language models

## Introduction: large language models and latent space representations

In the last years, a number of studies have shown that neural networks trained on large amounts of data tend to develop a latent space representation of the data they are trained on [@cite{liu2018latent,tschannen2019mutual,higgins2017beta}]. This means that the hidden activations of the neurons in the hidden layers of these neural networks can be seen as vectors in a high-dimensional space, and that these vectors tend to cluster together  .

This phenomenon applies to all neural networks, with and without autoencoders.

In this study, we investigated whether autoencoders can be used to train a latent space representation of the data in which the classes are separated from each other. 


Our aim was to make use of the latent space representations learned by autoencoders and compare it with other neural network architectures that have recently been shown to induce these representations. 


\subsection{[Related work]} \label{sec:[related-work]}


Many studies in unsupervised learning have shown how autoencoders can be used for classification tasks [@refs]. 

Autoencoders have also been used to learn latent space representations of data [@refs]. In particular, it has been shown that autoencoders can be used to learn a latent space representation of the data in which the classes are separated from each other [@refs]. 


This study investigates whether autoencoders can be used to train a latent space representation of the data in which the classes are separated from each other. 


Our aim was to make use of the latent space representations learned by autoencoders and compare it with other neural network architectures that have recently been shown to induce these representations. 


\subsection{[Contributions]}  
